---
title: "Concept c·ªßa Likelihood v√† ·ª©ng d·ª•ng c·ªßa n√≥"
excerpt: B√†i vi·∫øt n√†y d·ªãch l·∫°i m·ªôt paper c·ªßa t√°c gi·∫£ Etz v·ªÅ kh√°i ni·ªám likelihood (s·ª± h·ª£p l√Ω) trong l√Ω thuy·∫øt x√°c su·∫•t, ƒë·ªìng th·ªùi tr√¨nh b√†y m·ªôt s·ªë ·ª©ng d·ª•ng c∆° b·∫£n c·ªßa kh√°i ni·ªám n√†y.
tags: 
- mathematics
- probability
---

> üìì Paper g·ªëc:
> 
> Etz A. Introduction to the Concept of Likelihood and Its Applications. Advances in Methods and Practices in Psychological Science. 2018;1(1):60-69. doi:10.1177/2515245917744314

Likelihood (h·ª£p l√Ω) kh√¥ng ph·∫£i l√† x√°c su·∫•t (probability) m√† l√† m·ªôt ƒë·∫°i l∆∞·ª£ng t·ª∑ l·ªá v·ªõi x√°c su·∫•t. S·ª± h·ª£p l√Ω c·ªßa m·ªôt gi·∫£ thuy·∫øt $H$ (the likelihood of a hypothesis) khi bi·∫øt m·ªôt s·ªë d·ªØ li·ªáu li√™n quan $D$ (given some data) t·ª∑ l·ªá v·ªõi x√°c su·∫•t nh·∫≠n ƒë∆∞·ª£c $D$ n·∫øu $H$ l√† m·ªôt gi·∫£ thuy·∫øt ƒë√∫ng. G·ªçi $L$ l√† h√†m likelihood th√¨ $L(H)$ ƒë√°nh gi√° ƒë·ªô h·ª£p l√Ω c·ªßa gi·∫£ thuy·∫øt $H$:

$$
L(H) = K \times \Pr(D \mid H)
$$

V√¨ likelihood kh√¥ng ph·∫£i l√† x√°c su·∫•t n√™n n√≥ th∆∞·ªùng kh√¥ng tu√¢n theo c√°c quy t·∫Øc c·ªßa x√°c su·∫•t, m·ªôt trong s·ªë ƒë√≥ l√† likelihoods kh√¥ng c·∫ßn ph·∫£i c√≥ t·ªïng hay t√≠ch ph√¢n b·∫±ng 1.

M·ªôt ƒëi·ªÉm kh√°c bi·ªát quan tr·ªçng gi·ªØa probability v√† likelihood l√† nh·ªØng ƒë·∫°i l∆∞·ª£ng ƒë∆∞·ª£c c·ªë ƒë·ªãnh v√† nh·ªØng ƒë·∫°i l∆∞·ª£ng bi·∫øn thi√™n trong c√¥ng th·ª©c c·ªßa likelihood.
- Trong c√¥ng th·ª©c x√°c su·∫•t c√≥ ƒëi·ªÅu ki·ªán $\Pr(D \mid H)$ th√¨ gi·∫£ thuy·∫øt $H$ l√† c·ªë ƒë·ªãnh, nh∆∞ng d·ªØ li·ªáu $D$ c√≥ th·ªÉ thay ƒë·ªïi t√πy √Ω.
- Nh∆∞ng trong $L(H)$ th√¨ hypothesis $H$ c√≥ th·ªÉ thay ƒë·ªïi t√πy √Ω c√≤n data $D$ th√¨ c·ªë ƒë·ªãnh.

# Ti√™n ƒë·ªÅ v·ªÅ likelihood

> __The Law of Likelihood__
> 
> within the framework of a statistical model, a particular set of data supports one statistical hypothesis better than another if the likelihood of the first hypothesis, on the data, exceeds the likelihood of the second hypothesis

Gi·∫£ s·ª≠ c√≥ m·ªôt t·∫≠p data $D$, ta c√≥ hai gi·∫£ thuy·∫øt v·ªÅ ngu·ªìn g·ªëc sinh ra $D$ l√† $H_1$ v√† $H_2$. Gi·∫£ thuy·∫øt $H_1$ ƒë∆∞·ª£c cho l√† h·ª£p l√Ω h∆°n gi·∫£ thuy·∫øt $H_2$ c√≤n l·∫°i n·∫øu x√°c su·∫•t x·∫£y ra $D$ d·ª±a tr√™n gi·∫£ thuy·∫øt n√†y cao h∆°n gi·∫£ thuy·∫øt c√≤n l·∫°i: $\Pr(D \mid H_1) > \Pr(D \mid H_2)$. N·∫øu d·∫•u b·∫±ng x·∫£y ra th√¨ ta kh√¥ng c√≥ cƒÉn c·ª© (evidence) n√†o v·ªÅ vi·ªác $H_1$ h·ª£p l√Ω h∆°n $H_2$.

M·ªôt ƒë·∫°i l∆∞·ª£ng ƒë√°nh gi√° s·ª± h·ª£p l√Ω v·ªÅ m·∫∑t th·ªëng k√™ gi·ªØa $H_1$ v√† $H_2$ l√† t·ª∑ s·ªë c·ªßa s·ª± h·ª£p l√Ω c·ªßa ch√∫ng (ch√∫ √Ω h·∫±ng s·ªë $K$ trong c√¥ng th·ª©c c·ªßa $L(H)$ b·ªã kh·ª≠):

$$
\mathrm{LR}(H_1, H_2) = \frac{L(H_1)}{L(H_2)} = \frac{\Pr(D \mid H_1)}{\Pr(D \mid H_2)}
$$

> __Likelihood ƒë∆∞·ª£c d√πng ƒë·ªÉ so s√°nh__

Kh√¥ng nh∆∞ probability, c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng tr·ª±c ti·∫øp ƒë·ªÉ ƒë√°nh gi√° kh·∫£ nƒÉng x·∫£y ra c·ªßa m·ªôt bi·∫øn c·ªë, likelihood khi ƒë·ª©ng m·ªôt m√¨nh th√¨ n√≥ kh√¥ng th·ªÉ hi·ªán ƒë∆∞·ª£c ƒëi·ªÅu g√¨ nhi·ªÅu. Ch·ªâ khi c√≥ s·ª± so s√°nh gi·ªØa hai ho·∫∑c nhi·ªÅu likelihood v·ªõi nhau th√¨ likelihood m·ªõi c√≥ √Ω nghƒ©a.

__V√≠ d·ª• kinh ƒëi·ªÉn__

Binomial distribution: hai tham s·ªë $n$ v√† $p$: s·ªë l·∫ßn ph√©p th·ª≠ th√†nh c√¥ng v·ªõi x√°c su·∫•t $p$ trong $n$ l·∫ßn th·ª≠.

H√†m kh·ªëi x√°c su·∫•t probability mass function (PMF): $p^k$ x√°c su·∫•t th√†nh c√¥ng $k$ l·∫ßn, $(1-p)^{n-k}$, x√°c su·∫•t kh√¥ng th√†nh c√¥ng trong $n-k$ l·∫ßn th·ª≠, c√≥ $\binom{n}{k}$ th√≠ nghi·ªám cho ra $k$ l·∫ßn th√†nh c√¥ng v√† $n-k$ l·∫ßn th·ª≠. 

$$
f(k;n,p) = \Pr(k;n,p) = \Pr(X=k) = \binom{n}{k}p^k(1-p)^{n-k}
$$

Gi·∫£ s·ª≠ m·ªôt ƒë·ªìng xu ƒë∆∞·ª£c tung $n$ l·∫ßn v√† ta th·∫•y c√≥ $x$ l·∫ßn m·∫∑t ng·ª≠a (head) xu·∫•t hi·ªán v√† $n-x$ l·∫ßn m·∫∑t x·∫•p xu·∫•t hi·ªán. X√°c su·∫•t ƒë·ªÉ c√≥ $x$ m·∫∑t ng·ª≠a trong $n$ l·∫ßn tung ƒë·ªìng xu tu√¢n theo ph√¢n ph·ªëi Binomial

$$
\Pr(X=x;n,p)=\binom{n}{x}p^x(1-p)^{n-x}
$$

v·ªõi $p$ l√† x√°c su·∫•t xu·∫•t hi·ªán m·∫∑t ng·ª≠a.
Gi·∫£ s·ª≠ ƒë·ªìng xu c√¥ng b·∫±ng (x√°c su·∫•t xu·∫•t hi·ªán c·ªßa m·ªói m·∫∑t l√† $p=0.5$), x√°c su·∫•t ƒë·ªÉ c√≥ $06$ m·∫∑t ng·ª≠a xu·∫•t hi·ªán trong $10$ l·∫ßn th·ª≠ l√† 

$$
\Pr(X=6;n=10, p=0.5) = \frac{10!}{6! \times 4!}0.5^6 \times 0.5^4 \approx 0.21.
$$

N·∫øu ƒë·ªìng xu ƒë√£ b·ªã l√†m gian l·∫≠n v·ªõi x√°c su·∫•t su·∫•t hi·ªán m·∫∑t ng·ª≠a l√† $p = 0.75$, l√∫c n√†y x√°c su·∫•t ƒë·ªÉ xu·∫•t hi·ªán m·∫∑t ng·ª≠a 06 l·∫ßn trong 10 l·∫ßn th·ª≠ l√†

$$
\Pr(X=6;n=10, p=0.75) = \frac{10!}{6! \times 4!}0.75^6 \times 0.25^4 \approx 0.15.
$$

L√∫c n√†y ta c√≥ hai gi·∫£ thuy·∫øt:
- $H_1$: ƒë·ªìng xu c√¥ng b·∫±ng v·ªõi $p = 0.5$.
- $H_2$: ƒë·ªìng xu gian l·∫≠n v·ªõi $p=0.75$.

V·ªõi c√πng m·ªôt d·ªØ li·ªáu l√† m·∫∑t ng·ª≠a xu·∫•t hi·ªán 06 l·∫ßn trong s·ªë 10 l·∫ßn th·ª±c hi·ªán, ta c√≥:

$$
\begin{aligned}
L(H_1) &= \Pr(X=6 \mid p = 0.5),\\
L(H_2) &= \Pr(X=6 \mid p = 0.75).
\end{aligned}
$$

L√∫c n√†y likelihood ratio s·∫Ω l√† $\displaystyle  LR(H_1,H_2) \approx \frac{0.21}{0.15} \approx 1.4$.
